---
title: "CLIP Guided Multimodal Image Translation"
excerpt: "Multimodal Image translation with a BicycleGAN implemented from scratch. Added additional ability to guide generated outputs using CLIP posthoc, without any additional training whatsoever."
header:
  teaser: assets/images/projects/CLIPBCGAN sample.png
---

## CLIP Guided Multimodal Image Translation

Multimodal Image translation with a BicycleGAN implemented from scratch. Added additional ability to guide generated outputs using CLIP posthoc, without any additional training whatsoever.

### Key Features
- Implemented BicycleGAN from scratch
- Added CLIP guidance capability
- No additional training required for CLIP guidance
- Multimodal output generation

### Technical Details
- Built on BicycleGAN architecture for multimodal image translation
- Integrated CLIP model for post-hoc guidance
- Implemented custom loss functions for style control
- Developed prompt-based control mechanism

### Results
Below are example transformations using different text prompts:

![Shoe Transformations](assets/images/projects/CLIPBCGAN sample.png)
*Fig: Original shoes transformed using prompts "black shoe" and "metallic shoe"*

The results demonstrate:
- Successful color and style transformations
- Preservation of original shoe structure
- Prompt-guided modifications without retraining
- Multiple style variations from a single input

### Links
- [GitHub Repository](#) <!-- Add your repo link if public -->
- [Demo](#) <!-- Add demo link if available --> 